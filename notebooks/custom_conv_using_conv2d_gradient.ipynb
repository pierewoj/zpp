{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from tensorflow.python.ops import nn_ops, array_ops\n",
    "\n",
    "def conv2d(x, W, strides=(1,1,1,1), padding='VALID'):\n",
    "  return tf.nn.conv2d(x, W, strides, padding)\n",
    "\n",
    "#Wraper podstawiajacy \n",
    "def py_func(func, inp, Tout, stateful=True, name=None):\n",
    "    \n",
    "    # Nowa nazwa, żeby móc modyfikować nasz gradient\n",
    "    rnd_name = 'PyFuncGrad' + str(np.random.randint(0, 1E+8))\n",
    "    tf.RegisterGradient(rnd_name)(_BinGrad(inp[2], inp[3]))\n",
    "    \n",
    "    #Podstawienie gradientu\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": rnd_name}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n",
    "\n",
    "#Wrapper na wrappera\n",
    "def custom_conv2d(x, W, strides=(1,1,1,1), padding='VALID', name='conv'):\n",
    "    return py_func(conv, [x,W,strides,padding], [tf.float32])[0]\n",
    "    \n",
    "#Skopiowany gradient z conv2d\n",
    "def _BinGrad(strides, padding):\n",
    "    return lambda op, grad: [nn_ops.conv2d_backprop_input(array_ops.shape(op.inputs[0]), \n",
    "                                                          op.inputs[1], \n",
    "                                                          grad, \n",
    "                                                          strides,\n",
    "                                                          padding, \n",
    "                                                          False, \n",
    "                                                          'NHWC'),\n",
    "                            nn_ops.conv2d_backprop_filter(op.inputs[0],\n",
    "                                                          array_ops.shape(op.inputs[1]), \n",
    "                                                          grad,\n",
    "                                                          strides,\n",
    "                                                          padding,\n",
    "                                                          False,\n",
    "                                                          'NHWC'),\n",
    "                            op.inputs[2],op.inputs[3]]\n",
    "\n",
    "#Nasza operacja\n",
    "#result[batch,0:conv_height,0:conv_width,w_filter] -> suma konwolucji wszystkich channeli dla konkretnego batcha\n",
    "#i filtra\n",
    "def conv(x, W, strides, padding):\n",
    "    batches,x_height,x_width,x_channels = x.shape\n",
    "    W_height,W_width,w_channels,w_filters = W.shape\n",
    "    assert w_channels == x_channels\n",
    "    result = None\n",
    "    padding = padding.decode(\"utf-8\")\n",
    "    if padding == \"SAME\":\n",
    "        padh = W_height - x_height % W_height\n",
    "        padw = W_width - x_width % W_width\n",
    "        npad = ((0, 0), (0, padh), (0, padw), (0,0))\n",
    "        x = np.pad(x, pad_width=npad, mode='constant', constant_values=0)\n",
    "        batches,x_height,x_width,x_channels = x.shape\n",
    "    for batch in range(batches):\n",
    "        for w_filter in range(w_filters):\n",
    "            for channel in range(w_channels):\n",
    "                inp = x[batch,0:x_height,0:x_width,channel]\n",
    "                fil = np.rot90(W[0:W_height,0:W_width,channel,w_filter], 2)\n",
    "                conv_result = signal.convolve2d(inp, fil, 'valid')\n",
    "                conv_height,conv_width = conv_result.shape\n",
    "                if result is None:\n",
    "                    result = np.zeros((batches,conv_height,conv_width,w_filters), dtype=np.float32)\n",
    "                tmp = result[batch,0:conv_height,0:conv_width,w_filter]\n",
    "                result[batch,0:conv_height,0:conv_width,w_filter] = np.add(tmp, conv_result)\n",
    "    if not (strides==[1,1,1,1]).all():\n",
    "        b,h,w,c = result.shape\n",
    "        sh = strides[1]\n",
    "        sw = strides[2]\n",
    "        dh = [i for i in range(h) if i%sh != 0]\n",
    "        dw = [i for i in range(w) if i%sw != 0]\n",
    "        result = np.delete(result, dh, 1)\n",
    "        result = np.delete(result, dw, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test na feed forward, jeden input, jeden channel, jeden weight filter\n",
    "def feedforward_1i_1ch_1w():\n",
    "    x = tf.placeholder(tf.float32, [None, 9])\n",
    "    x_reshaped = tf.reshape(x, [-1,3,3,1])\n",
    "    w = np.zeros([2,2,1,1])\n",
    "    w[0:2,0:2,0,0] = np.vstack(([1,0],[0,0]))\n",
    "    W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    numbers = np.reshape(np.array([1,2,3,4,5,6,7,8,9], dtype=np.float32),(1,9))\n",
    "    result = custom_conv2d(x_reshaped, W_conv1, strides=(1,3,2,1), padding='VALID')\n",
    "    result_n = conv2d(x_reshaped, W_conv1, strides=(1,3,2,1), padding='VALID')\n",
    "    result_conv = result.eval(session=sess, feed_dict={x: numbers})\n",
    "    result_norm = result_n.eval(session=sess, feed_dict={x: numbers})\n",
    "    assert result_conv.shape == result_norm.shape\n",
    "    assert np.linalg.norm(result_conv-result_norm) < 0.01\n",
    "feedforward_1i_1ch_1w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#test na feed forward, jeden input, jeden channel, jeden weight filter\n",
    "def feedforward_1i_1ch_1w():\n",
    "    x = tf.placeholder(tf.float32, [None, 42])\n",
    "    x_reshaped = tf.reshape(x, [-1,7,6,1])\n",
    "    w = np.zeros([3,4,1,1])\n",
    "    #w[0:2,0:2,0,0] = np.vstack(([1,0],[0,0]))\n",
    "    W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    numbers = np.reshape(np.zeros(42, dtype=np.float32),(1,42))\n",
    "    result_n = conv2d(x_reshaped, W_conv1, strides=[1,2,4,1], padding='VALID')\n",
    "    result_norm = result_n.eval(session=sess, feed_dict={x: numbers})\n",
    "    print(result_norm.shape)\n",
    "feedforward_1i_1ch_1w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test na feed forward, jeden input, dwa channele, dwa weight filter\n",
    "def feedforward_1i_2ch_2w():\n",
    "    x = tf.placeholder(tf.float32, [None, 9])\n",
    "    x_reshaped = tf.reshape(x, [-1,3,3,2])\n",
    "    w = np.zeros([2,2,2,2])\n",
    "    w[0:2,0:2,0,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,1,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,0,1] = np.vstack(([1,1],[1,1]))\n",
    "    W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    numbers = np.reshape(np.array([1,2,3,4,5,6,7,8,9], dtype=np.float32),(1,9))\n",
    "    inputs = np.vstack((numbers,numbers));\n",
    "    result = custom_conv2d(x_reshaped, W_conv1)\n",
    "    result_n = conv2d(x_reshaped, W_conv1)\n",
    "    result_conv = result.eval(session=sess, feed_dict={x: inputs})\n",
    "    result_norm = result_n.eval(session=sess, feed_dict={x: inputs})\n",
    "    assert result_conv.shape == result_norm.shape\n",
    "    assert np.linalg.norm(result_conv-result_norm) < 0.01\n",
    "feedforward_1i_2ch_2w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test na feed forward, jeden input, dwa channele, dwa weight filter\n",
    "def feedforward_2i_2ch_2w():\n",
    "    x = tf.placeholder(tf.float32, [None, 9])\n",
    "    x_reshaped = tf.reshape(x, [-1,3,3,2])\n",
    "    w = np.zeros([2,2,2,2])\n",
    "    w[0:2,0:2,0,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,1,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,0,1] = np.vstack(([1,1],[1,1]))\n",
    "    W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    numbers = np.reshape(np.array([1,2,3,4,5,6,7,8,9], dtype=np.float32),(1,9))\n",
    "    inputs = np.vstack((numbers,numbers,numbers,numbers));\n",
    "    result = custom_conv2d(x_reshaped, W_conv1)\n",
    "    result_n = conv2d(x_reshaped, W_conv1)\n",
    "    result_conv = result.eval(session=sess, feed_dict={x: inputs})\n",
    "    result_norm = result_n.eval(session=sess, feed_dict={x: inputs})\n",
    "    assert result_conv.shape == result_norm.shape\n",
    "    assert np.linalg.norm(result_conv-result_norm) < 0.01\n",
    "feedforward_2i_2ch_2w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test na gradienty, jeden input, jeden channel, jeden weight filter\n",
    "def gradient_1i_1ch_1w():\n",
    "    x = tf.placeholder(tf.float32, [None, 9])\n",
    "    x_reshaped = tf.reshape(x, [-1,3,3,1])\n",
    "    w = np.zeros([2,2,1,1])\n",
    "    w[0:2,0:2,0,0] = np.vstack(([0.1,0.2],[1,0.3]))\n",
    "    W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    numbers = np.reshape(np.array([2,1,1,1,1,1,1,2,1], dtype=np.float32),(1,9))\n",
    "    result = custom_conv2d(x_reshaped, W_conv1)\n",
    "    result_n = conv2d(x_reshaped, W_conv1)\n",
    "\n",
    "    var_grad = tf.gradients(result, W_conv1)[0]\n",
    "    var_grad_n = tf.gradients(result_n, W_conv1)[0]\n",
    "    gradients = var_grad.eval(session=sess, feed_dict={x: np.reshape(numbers,(1,9))})\n",
    "    gradients_n = var_grad_n.eval(session=sess, feed_dict={x: np.reshape(numbers,(1,9))})\n",
    "    assert np.linalg.norm(gradients-gradients_n) < 0.01\n",
    "gradient_1i_1ch_1w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test na feed forward, jeden input, dwa channele, dwa weight filter\n",
    "def gradient_1i_2ch_2w():\n",
    "    x = tf.placeholder(tf.float32, [None, 9])\n",
    "    x_reshaped = tf.reshape(x, [-1,3,3,2])\n",
    "    w = np.zeros([2,2,2,2])\n",
    "    w[0:2,0:2,0,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,1,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,0,1] = np.vstack(([1,1],[1,1]))\n",
    "    W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    numbers = np.reshape(np.array([1,2,3,4,5,6,7,8,9], dtype=np.float32),(1,9))\n",
    "    inputs = np.vstack((numbers,numbers));\n",
    "    result = custom_conv2d(x_reshaped, W_conv1)\n",
    "    result_n = conv2d(x_reshaped, W_conv1)\n",
    "    \n",
    "    var_grad = tf.gradients(result, W_conv1)[0]\n",
    "    var_grad_n = tf.gradients(result_n, W_conv1)[0]\n",
    "    gradients = var_grad.eval(session=sess, feed_dict={x: inputs})\n",
    "    gradients_n = var_grad_n.eval(session=sess, feed_dict={x: inputs})\n",
    "    assert np.linalg.norm(gradients-gradients_n) < 0.01\n",
    "gradient_1i_2ch_2w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test na feed forward, dwa inputy, dwa channele, dwa weight filter\n",
    "def gradient_2i_2ch_2w():\n",
    "    x = tf.placeholder(tf.float32, [None, 9])\n",
    "    x_reshaped = tf.reshape(x, [-1,3,3,2])\n",
    "    w = np.zeros([2,2,2,2])\n",
    "    w[0:2,0:2,0,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,1,0] = np.vstack(([1,1],[1,1]))\n",
    "    w[0:2,0:2,0,1] = np.vstack(([1,1],[1,1]))\n",
    "    W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    numbers = np.reshape(np.array([1,2,3,4,5,6,7,8,9], dtype=np.float32),(1,9))\n",
    "    inputs = np.vstack((numbers,numbers,numbers,numbers));\n",
    "    result = custom_conv2d(x_reshaped, W_conv1)\n",
    "    result_n = conv2d(x_reshaped, W_conv1)\n",
    "    \n",
    "    var_grad = tf.gradients(result, W_conv1)[0]\n",
    "    var_grad_n = tf.gradients(result_n, W_conv1)[0]\n",
    "    gradients = var_grad.eval(session=sess, feed_dict={x: inputs})\n",
    "    gradients_n = var_grad_n.eval(session=sess, feed_dict={x: inputs})\n",
    "    assert np.linalg.norm(gradients-gradients_n) < 0.01\n",
    "gradient_2i_2ch_2w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

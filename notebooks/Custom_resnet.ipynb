{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example two-layer classifier models\n",
    "\n",
    "Below example code is given for creating instances of the CIFAR-10 and CIFAR-100 data provider objects and using them to train simple two-layer feedforward network models with rectified linear activations in TensorFlow. You may wish to use this code as a starting point for your own experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 50\n",
    "valid_batch_size = 50\n",
    "res_blocks_num = 2\n",
    "weight_decay = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mlp.data_providers import CIFAR10DataProvider, CIFAR100DataProvider\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_file_to_write(name):\n",
    "    global train_writer\n",
    "    global valid_writer\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    train_writer = tf.summary.FileWriter(os.path.join('log-resnet/',name, timestamp, 'train'))\n",
    "    valid_writer = tf.summary.FileWriter(os.path.join('log-resnet/', name, timestamp, 'valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = CIFAR10DataProvider('train', batch_size=train_batch_size)\n",
    "re = train_data.inputs.reshape((40000, -1, 3), order='F')\n",
    "train_data.inputs = re.reshape((40000, 32, 32, 3))\n",
    "\n",
    "\n",
    "\n",
    "valid_data = CIFAR10DataProvider('valid', batch_size=valid_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(inputs, input_dim, output_dim, nonlinearity=tf.nn.relu):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    outputs = nonlinearity(tf.matmul(inputs, weights) + biases)\n",
    "    return outputs\n",
    "\n",
    "def create_variables(name, shape, initializer=tf.contrib.layers.xavier_initializer(), is_fc_layer=False):\n",
    "    '''\n",
    "    :param name: A string. The name of the new variable\n",
    "    :param shape: A list of dimensions\n",
    "    :param initializer: User Xavier as default.\n",
    "    :param is_fc_layer: Want to create fc layer variable? May use different weight_decay for fc\n",
    "    layers.\n",
    "    :return: The created variable\n",
    "    '''\n",
    "    \n",
    "    if is_fc_layer is True:\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=weight_decay)\n",
    "    else:\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=weight_decay)\n",
    "\n",
    "    new_variables = tf.get_variable(name, shape=shape, initializer=initializer,\n",
    "                                    regularizer=regularizer)\n",
    "    return new_variables\n",
    "\n",
    "\n",
    "def batch_normalization_layer(input_layer, dimension):\n",
    "    '''\n",
    "    Helper function to do batch normalziation\n",
    "    :param input_layer: 4D tensor\n",
    "    :param dimension: input_layer.get_shape().as_list()[-1]. The depth of the 4D tensor\n",
    "    :return: the 4D tensor after being normalized\n",
    "    '''\n",
    "    mean, variance = tf.nn.moments(input_layer, axes=[0, 1, 2])\n",
    "    beta = tf.get_variable('beta', dimension, tf.float32,\n",
    "                               initializer=tf.constant_initializer(0.0, tf.float32))\n",
    "    gamma = tf.get_variable('gamma', dimension, tf.float32,\n",
    "                                initializer=tf.constant_initializer(1.0, tf.float32))\n",
    "    bn_layer = tf.nn.batch_normalization(input_layer, mean, variance, beta, gamma, BN_EPSILON)\n",
    "\n",
    "    return bn_layer\n",
    "\n",
    "\n",
    "def conv_bn_relu_layer(input_layer, filter_shape, stride):\n",
    "    '''\n",
    "    A helper function to conv, batch normalize and relu the input tensor sequentially\n",
    "    :param input_layer: 4D tensor\n",
    "    :param filter_shape: list. [filter_height, filter_width, filter_depth, filter_number]\n",
    "    :param stride: stride size for conv\n",
    "    :return: 4D tensor. Y = Relu(batch_normalize(conv(X)))\n",
    "    '''\n",
    "\n",
    "    out_channel = filter_shape[-1]\n",
    "    filter = create_variables(name='conv', shape=filter_shape)\n",
    "\n",
    "    conv_layer = tf.nn.conv2d(input_layer, filter, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    bn_layer = batch_normalization_layer(conv_layer, out_channel)\n",
    "\n",
    "    output = tf.nn.relu(bn_layer)\n",
    "    return output\n",
    "\n",
    "\n",
    "def bn_relu_conv_layer(input_layer, filter_shape, stride):\n",
    "    '''\n",
    "    A helper function to batch normalize, relu and conv the input layer sequentially\n",
    "    :param input_layer: 4D tensor\n",
    "    :param filter_shape: list. [filter_height, filter_width, filter_depth, filter_number]\n",
    "    :param stride: stride size for conv\n",
    "    :return: 4D tensor. Y = conv(Relu(batch_normalize(X)))\n",
    "    '''\n",
    "\n",
    "    in_channel = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    bn_layer = batch_normalization_layer(input_layer, in_channel)\n",
    "    relu_layer = tf.nn.relu(bn_layer)\n",
    "\n",
    "    filter = create_variables(name='conv', shape=filter_shape)\n",
    "    conv_layer = tf.nn.conv2d(relu_layer, filter, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\n",
    "def residual_block(input_layer, output_channel, first_block=False):\n",
    "    '''\n",
    "    Defines a residual block in ResNet\n",
    "    :param input_layer: 4D tensor\n",
    "    :param output_channel: int. return_tensor.get_shape().as_list()[-1] = output_channel\n",
    "    :param first_block: if this is the first residual block of the whole network\n",
    "    :return: 4D tensor.\n",
    "    '''\n",
    "    input_channel = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    # When it's time to \"shrink\" the image size, we use stride = 2\n",
    "    if input_channel * 2 == output_channel:\n",
    "        increase_dim = True\n",
    "        stride = 2\n",
    "    elif input_channel == output_channel:\n",
    "        increase_dim = False\n",
    "        stride = 1\n",
    "    else:\n",
    "        raise ValueError('Output and input channel does not match in residual blocks!!!')\n",
    "\n",
    "    # The first conv layer of the first residual block does not need to be normalized and relu-ed.\n",
    "    with tf.variable_scope('conv1_in_block'):\n",
    "        if first_block:\n",
    "            filter = create_variables(name='conv', shape=[3, 3, input_channel, output_channel])\n",
    "            conv1 = tf.nn.conv2d(input_layer, filter=filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        else:\n",
    "            conv1 = bn_relu_conv_layer(input_layer, [3, 3, input_channel, output_channel], stride)\n",
    "\n",
    "    with tf.variable_scope('conv2_in_block'):\n",
    "        conv2 = bn_relu_conv_layer(conv1, [3, 3, output_channel, output_channel], 1)\n",
    "\n",
    "    # When the channels of input layer and conv2 does not match, we add zero pads to increase the\n",
    "    #  depth of input layers\n",
    "    if increase_dim is True:\n",
    "        pooled_input = tf.nn.avg_pool(input_layer, ksize=[1, 2, 2, 1],\n",
    "                                      strides=[1, 2, 2, 1], padding='VALID')\n",
    "        padded_input = tf.pad(pooled_input, [[0, 0], [0, 0], [0, 0], [input_channel // 2,\n",
    "                                                                     input_channel // 2]])\n",
    "    else:\n",
    "        padded_input = input_layer\n",
    "\n",
    "    output = conv2 + padded_input\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "IMG_DEPTH = 3\n",
    "NUM_CLASS = 10\n",
    "\n",
    "BN_EPSILON=0.001\n",
    "\n",
    "reuse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    #num layers = 6n + 2\n",
    "    global init\n",
    "    global summary_op\n",
    "    global error\n",
    "    global accuracy\n",
    "    global outputs\n",
    "    global train_step\n",
    "    global inputs\n",
    "    global targets\n",
    "    global outputs\n",
    "    \n",
    "    inputs = tf.placeholder(tf.float32,[train_batch_size, IMG_HEIGHT,\n",
    "                                                        IMG_WIDTH, IMG_DEPTH], 'inputs')\n",
    "    targets = tf.placeholder(tf.float32, [None, train_data.num_classes], 'targets')\n",
    "    #def inference(input_tensor_batch, n, reuse):\n",
    "\n",
    "    layers = []\n",
    "    with tf.variable_scope('conv0', reuse=reuse):\n",
    "        conv0 = conv_bn_relu_layer(inputs, [3, 3, 3, 16], 1)\n",
    "        layers.append(conv0)\n",
    "\n",
    "    for i in range(n):\n",
    "        with tf.variable_scope('conv1_%d' %i, reuse=reuse):\n",
    "            if i == 0:\n",
    "                conv11 = residual_block(layers[-1], 16, first_block=True)\n",
    "            else:\n",
    "                conv11 = residual_block(layers[-1], 16)\n",
    "            layers.append(conv11)\n",
    "\n",
    "    for i in range(n):\n",
    "        with tf.variable_scope('conv2_%d' %i, reuse=reuse):\n",
    "            conv2 = residual_block(layers[-1], 32)\n",
    "            layers.append(conv2)\n",
    "\n",
    "    for i in range(n):\n",
    "        with tf.variable_scope('conv3_%d' %i, reuse=reuse):\n",
    "            conv3 = residual_block(layers[-1], 64)\n",
    "            layers.append(conv3)\n",
    "        assert conv3.get_shape().as_list()[1:] == [8, 8, 64]\n",
    "\n",
    "    with tf.variable_scope('fc', reuse=reuse):\n",
    "        in_channel = layers[-1].get_shape().as_list()[-1]\n",
    "        bn_layer = batch_normalization_layer(layers[-1], in_channel)\n",
    "        relu_layer = tf.nn.relu(bn_layer)\n",
    "        global_pool = tf.reduce_mean(relu_layer, [1, 2])\n",
    "\n",
    "        assert global_pool.get_shape().as_list()[-1:] == [64]\n",
    "        outputs = fully_connected_layer(global_pool, 64, 10, tf.identity)\n",
    "        \n",
    "    with tf.name_scope('error'):\n",
    "        error = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(outputs, targets))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(\n",
    "                tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), \n",
    "                tf.float32))\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        opt = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.9)\n",
    "        train_step = opt.minimize(error)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    tf.summary.scalar('error', error)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_session(name, num_epoch):\n",
    "    open_file_to_write(name)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        valid_inputs = valid_data.inputs\n",
    "        valid_targets = valid_data.to_one_of_k(valid_data.targets) \n",
    "        sess.run(init)\n",
    "        for e in range(num_epoch):\n",
    "            running_error = 0.\n",
    "            running_accuracy = 0.\n",
    "            start = time.time()\n",
    "            for b, (input_batch, target_batch) in enumerate(train_data):\n",
    "                _, batch_error, batch_acc, summary = sess.run(\n",
    "                    [train_step, error, accuracy, summary_op], \n",
    "                    feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                \n",
    "                running_error += batch_error\n",
    "                running_accuracy += batch_acc\n",
    "\n",
    "                train_writer.add_summary(summary, e * train_data.num_batches + b)\n",
    "                \n",
    "            running_error /= train_data.num_batches\n",
    "            running_accuracy /= train_data.num_batches\n",
    "            print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f}, time(train)={3:.2f}'\n",
    "                  .format(e + 1, running_error, running_accuracy, time.time() - start))\n",
    "            if (e + 1) % 5 == 0:\n",
    "                valid_error = 0.\n",
    "                valid_accuracy = 0.\n",
    "                for b, (input_batch, target_batch) in enumerate(valid_data):\n",
    "                    input_batch = input_batch.reshape((50, IMG_HEIGHT * IMG_WIDTH, IMG_DEPTH), order='F')\n",
    "                    input_batch = input_batch.reshape((50, IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH))\n",
    "                    \n",
    "                    batch_error, batch_acc, summary = sess.run(\n",
    "                        [error, accuracy, summary_op], \n",
    "                        feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                    valid_error += batch_error\n",
    "                    valid_accuracy += batch_acc\n",
    "                    valid_writer.add_summary(summary, e * train_data.num_batches + b)\n",
    "                valid_error /= valid_data.num_batches\n",
    "                valid_accuracy /= valid_data.num_batches\n",
    "                print('                 err(valid)={0:.2f} acc(valid)={1:.2f}'\n",
    "                       .format(valid_error, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.47 acc(train)=0.47, time(train)=826.51\n",
      "End of epoch 02: err(train)=1.04 acc(train)=0.63, time(train)=1755.81\n",
      "End of epoch 03: err(train)=0.86 acc(train)=0.70, time(train)=734.55\n",
      "End of epoch 04: err(train)=0.74 acc(train)=0.74, time(train)=741.39\n",
      "End of epoch 05: err(train)=0.66 acc(train)=0.77, time(train)=4308.91\n",
      "                 err(valid)=0.73 acc(valid)=0.75\n",
      "End of epoch 06: err(train)=0.59 acc(train)=0.79, time(train)=7749.84\n",
      "End of epoch 07: err(train)=0.54 acc(train)=0.81, time(train)=1500.17\n",
      "End of epoch 08: err(train)=0.48 acc(train)=0.83, time(train)=951.31\n",
      "End of epoch 09: err(train)=0.44 acc(train)=0.85, time(train)=35530.32\n",
      "End of epoch 10: err(train)=0.40 acc(train)=0.86, time(train)=816.48\n",
      "                 err(valid)=0.68 acc(valid)=0.78\n",
      "End of epoch 11: err(train)=0.37 acc(train)=0.87, time(train)=814.20\n",
      "End of epoch 12: err(train)=0.33 acc(train)=0.88, time(train)=810.37\n",
      "End of epoch 13: err(train)=0.30 acc(train)=0.90, time(train)=816.25\n",
      "End of epoch 14: err(train)=0.27 acc(train)=0.90, time(train)=834.43\n",
      "End of epoch 15: err(train)=0.25 acc(train)=0.92, time(train)=816.98\n",
      "                 err(valid)=0.77 acc(valid)=0.77\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(2)\n",
    "run_session('2-layers', 15)\n",
    "\n",
    "#learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.44 acc(train)=0.47, time(train)=2799.49\n",
      "End of epoch 02: err(train)=0.99 acc(train)=0.65, time(train)=2746.39\n",
      "End of epoch 03: err(train)=0.80 acc(train)=0.72, time(train)=1829.34\n",
      "End of epoch 04: err(train)=0.67 acc(train)=0.76, time(train)=1593.61\n",
      "End of epoch 05: err(train)=0.59 acc(train)=0.80, time(train)=1596.94\n",
      "                 err(valid)=0.67 acc(valid)=0.77\n",
      "End of epoch 06: err(train)=0.51 acc(train)=0.82, time(train)=1593.99\n",
      "End of epoch 07: err(train)=0.46 acc(train)=0.84, time(train)=1595.90\n",
      "End of epoch 08: err(train)=0.40 acc(train)=0.86, time(train)=1601.28\n",
      "End of epoch 09: err(train)=0.35 acc(train)=0.88, time(train)=1597.24\n",
      "End of epoch 10: err(train)=0.31 acc(train)=0.89, time(train)=1596.28\n",
      "                 err(valid)=0.66 acc(valid)=0.79\n",
      "End of epoch 11: err(train)=0.27 acc(train)=0.91, time(train)=1593.59\n",
      "End of epoch 12: err(train)=0.24 acc(train)=0.92, time(train)=1593.30\n",
      "End of epoch 13: err(train)=0.21 acc(train)=0.93, time(train)=1594.06\n",
      "End of epoch 14: err(train)=0.18 acc(train)=0.94, time(train)=1591.79\n",
      "End of epoch 15: err(train)=0.16 acc(train)=0.94, time(train)=1598.24\n",
      "                 err(valid)=0.76 acc(valid)=0.79\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(5)\n",
    "run_session('5-layers', 15)\n",
    "\n",
    "#learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.41 acc(train)=0.44, time(train)=1070.39\n",
      "End of epoch 02: err(train)=1.04 acc(train)=0.63, time(train)=1264.53\n",
      "End of epoch 03: err(train)=0.85 acc(train)=0.70, time(train)=1195.95\n",
      "End of epoch 04: err(train)=0.73 acc(train)=0.74, time(train)=1179.67\n",
      "End of epoch 05: err(train)=0.64 acc(train)=0.78, time(train)=1301.74\n",
      "                 err(valid)=0.72 acc(valid)=0.75\n",
      "End of epoch 06: err(train)=0.58 acc(train)=0.80, time(train)=1234.25\n",
      "End of epoch 07: err(train)=0.52 acc(train)=0.82, time(train)=1148.95\n",
      "End of epoch 08: err(train)=0.47 acc(train)=0.84, time(train)=1150.13\n",
      "End of epoch 09: err(train)=0.43 acc(train)=0.85, time(train)=1391.50\n",
      "End of epoch 10: err(train)=0.39 acc(train)=0.86, time(train)=1545.44\n",
      "                 err(valid)=0.69 acc(valid)=0.77\n",
      "End of epoch 11: err(train)=0.36 acc(train)=0.87, time(train)=1469.35\n",
      "End of epoch 12: err(train)=0.32 acc(train)=0.89, time(train)=1461.87\n",
      "End of epoch 13: err(train)=0.29 acc(train)=0.90, time(train)=1339.91\n",
      "End of epoch 14: err(train)=0.26 acc(train)=0.91, time(train)=1183.74\n",
      "End of epoch 15: err(train)=0.24 acc(train)=0.92, time(train)=1181.36\n",
      "                 err(valid)=0.81 acc(valid)=0.76\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(2)\n",
    "run_session('2-layers-0.01', 15)\n",
    "\n",
    "#learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.47 acc(train)=0.46, time(train)=1274.59\n",
      "End of epoch 02: err(train)=1.04 acc(train)=0.63, time(train)=1272.13\n",
      "End of epoch 03: err(train)=0.86 acc(train)=0.69, time(train)=3487.52\n",
      "End of epoch 04: err(train)=0.74 acc(train)=0.74, time(train)=1532.14\n",
      "End of epoch 05: err(train)=0.65 acc(train)=0.77, time(train)=1315.42\n",
      "                 err(valid)=0.73 acc(valid)=0.75\n",
      "End of epoch 06: err(train)=0.58 acc(train)=0.80, time(train)=1363.28\n",
      "End of epoch 07: err(train)=0.53 acc(train)=0.81, time(train)=1312.79\n",
      "End of epoch 08: err(train)=0.48 acc(train)=0.83, time(train)=1325.56\n",
      "End of epoch 09: err(train)=0.44 acc(train)=0.84, time(train)=1257.22\n",
      "End of epoch 10: err(train)=0.40 acc(train)=0.86, time(train)=1410.84\n",
      "                 err(valid)=0.65 acc(valid)=0.79\n",
      "End of epoch 11: err(train)=0.36 acc(train)=0.87, time(train)=1344.40\n",
      "End of epoch 12: err(train)=0.33 acc(train)=0.88, time(train)=1423.69\n",
      "End of epoch 13: err(train)=0.30 acc(train)=0.89, time(train)=1280.14\n",
      "End of epoch 14: err(train)=0.27 acc(train)=0.91, time(train)=1305.75\n",
      "End of epoch 15: err(train)=0.24 acc(train)=0.91, time(train)=1432.39\n",
      "                 err(valid)=0.73 acc(valid)=0.78\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(2)\n",
    "run_session('2-layers-0.005', 15)\n",
    "\n",
    "#learning rate 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.40 acc(train)=0.49, time(train)=1798.29\n",
      "End of epoch 02: err(train)=0.97 acc(train)=0.65, time(train)=1910.14\n",
      "End of epoch 03: err(train)=0.78 acc(train)=0.73, time(train)=1878.19\n",
      "End of epoch 04: err(train)=0.65 acc(train)=0.77, time(train)=1657.56\n",
      "End of epoch 05: err(train)=0.57 acc(train)=0.80, time(train)=1827.13\n",
      "                 err(valid)=0.67 acc(valid)=0.76\n",
      "End of epoch 06: err(train)=0.49 acc(train)=0.83, time(train)=2003.08\n",
      "End of epoch 07: err(train)=0.43 acc(train)=0.85, time(train)=1773.37\n",
      "End of epoch 08: err(train)=0.38 acc(train)=0.87, time(train)=1947.42\n",
      "End of epoch 09: err(train)=0.33 acc(train)=0.88, time(train)=1780.66\n",
      "End of epoch 10: err(train)=0.29 acc(train)=0.90, time(train)=1621.76\n",
      "                 err(valid)=0.64 acc(valid)=0.80\n",
      "End of epoch 11: err(train)=0.25 acc(train)=0.91, time(train)=1597.87\n",
      "End of epoch 12: err(train)=0.22 acc(train)=0.92, time(train)=1587.39\n",
      "End of epoch 13: err(train)=0.19 acc(train)=0.93, time(train)=1661.87\n",
      "End of epoch 14: err(train)=0.16 acc(train)=0.94, time(train)=1627.24\n",
      "End of epoch 15: err(train)=0.15 acc(train)=0.95, time(train)=1721.55\n",
      "                 err(valid)=0.78 acc(valid)=0.79\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(5)\n",
    "run_session('5-layers-0.05', 15)\n",
    "\n",
    "#learning rate 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.01 acc(train)=0.26, time(train)=1317.31\n",
      "End of epoch 02: err(train)=1.11 acc(train)=0.61, time(train)=2211.22\n",
      "End of epoch 03: err(train)=0.86 acc(train)=0.70, time(train)=1880.57\n",
      "End of epoch 04: err(train)=0.71 acc(train)=0.75, time(train)=1590.21\n",
      "End of epoch 05: err(train)=0.61 acc(train)=0.78, time(train)=1585.58\n",
      "                 err(valid)=0.67 acc(valid)=0.77\n",
      "End of epoch 06: err(train)=0.54 acc(train)=0.81, time(train)=1742.09\n",
      "End of epoch 07: err(train)=0.47 acc(train)=0.84, time(train)=2027.96\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(5)\n",
    "run_session('5-layers-0.001', 15)\n",
    "\n",
    "#learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

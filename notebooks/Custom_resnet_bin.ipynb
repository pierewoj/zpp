{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example two-layer classifier models\n",
    "\n",
    "Below example code is given for creating instances of the CIFAR-10 and CIFAR-100 data provider objects and using them to train simple two-layer feedforward network models with rectified linear activations in TensorFlow. You may wish to use this code as a starting point for your own experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 50\n",
    "valid_batch_size = 50\n",
    "res_blocks_num = 2\n",
    "weight_decay = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mlp.data_providers import CIFAR10DataProvider\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_file_to_write(name):\n",
    "    global train_writer\n",
    "    global valid_writer\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    train_writer = tf.summary.FileWriter(os.path.join('log-bin-resnet/',name, timestamp, 'train'))\n",
    "    valid_writer = tf.summary.FileWriter(os.path.join('log-bin-resnet/', name, timestamp, 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_bin(x, filter, strides, padding):\n",
    "    G = tf.get_default_graph()\n",
    "    with G.gradient_override_map({\"Sign\": \"Identity\"}):\n",
    "                w_shape = tf.shape(filter)\n",
    "                n = tf.cast(tf.reduce_prod(w_shape[0:-1]),tf.float32) \n",
    "                abs = tf.abs(filter)\n",
    "                \n",
    "                a = tf.stop_gradient(tf.reduce_sum(abs, [0,1,2])/n) #wektor\n",
    "                # Przy tej implementacji siec sie uczy.\n",
    "                #a = tf.stop_gradient(tf.reduce_sum(abs, [0,1,2,3])/n) taka sama alfa dla wszystkich, skalar\n",
    "                # \n",
    "                \n",
    "                return tf.nn.conv2d(x, tf.sign(filter/a), strides, padding)*a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = CIFAR10DataProvider('train', batch_size=train_batch_size)\n",
    "re = train_data.inputs.reshape((40000, -1, 3), order='F')\n",
    "train_data.inputs = re.reshape((40000, 32, 32, 3))\n",
    "\n",
    "\n",
    "\n",
    "valid_data = CIFAR10DataProvider('valid', batch_size=valid_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(inputs, input_dim, output_dim, nonlinearity=tf.nn.relu):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    outputs = nonlinearity(tf.matmul(inputs, weights) + biases)\n",
    "    return outputs\n",
    "\n",
    "def create_variables(name, shape, initializer=tf.contrib.layers.xavier_initializer(), is_fc_layer=False):\n",
    "    '''\n",
    "    :param name: A string. The name of the new variable\n",
    "    :param shape: A list of dimensions\n",
    "    :param initializer: User Xavier as default.\n",
    "    :param is_fc_layer: Want to create fc layer variable? May use different weight_decay for fc\n",
    "    layers.\n",
    "    :return: The created variable\n",
    "    '''\n",
    "    \n",
    "    if is_fc_layer is True:\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=weight_decay)\n",
    "    else:\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=weight_decay)\n",
    "\n",
    "    new_variables = tf.get_variable(name, shape=shape, initializer=initializer,\n",
    "                                    regularizer=regularizer)\n",
    "    return new_variables\n",
    "\n",
    "\n",
    "def batch_normalization_layer(input_layer, dimension):\n",
    "    '''\n",
    "    Helper function to do batch normalziation\n",
    "    :param input_layer: 4D tensor\n",
    "    :param dimension: input_layer.get_shape().as_list()[-1]. The depth of the 4D tensor\n",
    "    :return: the 4D tensor after being normalized\n",
    "    '''\n",
    "    mean, variance = tf.nn.moments(input_layer, axes=[0, 1, 2])\n",
    "    beta = tf.get_variable('beta', dimension, tf.float32,\n",
    "                               initializer=tf.constant_initializer(0.0, tf.float32))\n",
    "    gamma = tf.get_variable('gamma', dimension, tf.float32,\n",
    "                                initializer=tf.constant_initializer(1.0, tf.float32))\n",
    "    bn_layer = tf.nn.batch_normalization(input_layer, mean, variance, beta, gamma, BN_EPSILON)\n",
    "\n",
    "    return bn_layer\n",
    "\n",
    "\n",
    "def conv_bn_relu_layer(input_layer, filter_shape, stride):\n",
    "    '''\n",
    "    A helper function to conv, batch normalize and relu the input tensor sequentially\n",
    "    :param input_layer: 4D tensor\n",
    "    :param filter_shape: list. [filter_height, filter_width, filter_depth, filter_number]\n",
    "    :param stride: stride size for conv\n",
    "    :return: 4D tensor. Y = Relu(batch_normalize(conv(X)))\n",
    "    '''\n",
    "\n",
    "    out_channel = filter_shape[-1]\n",
    "    filter = create_variables(name='conv', shape=filter_shape)\n",
    "\n",
    "    conv_layer = conv_bin(input_layer, filter, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    bn_layer = batch_normalization_layer(conv_layer, out_channel)\n",
    "\n",
    "    output = tf.nn.relu(bn_layer)\n",
    "    return output\n",
    "\n",
    "\n",
    "def bn_relu_conv_layer(input_layer, filter_shape, stride):\n",
    "    '''\n",
    "    A helper function to batch normalize, relu and conv the input layer sequentially\n",
    "    :param input_layer: 4D tensor\n",
    "    :param filter_shape: list. [filter_height, filter_width, filter_depth, filter_number]\n",
    "    :param stride: stride size for conv\n",
    "    :return: 4D tensor. Y = conv(Relu(batch_normalize(X)))\n",
    "    '''\n",
    "\n",
    "    in_channel = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    bn_layer = batch_normalization_layer(input_layer, in_channel)\n",
    "    relu_layer = tf.nn.relu(bn_layer)\n",
    "\n",
    "    filter = create_variables(name='conv', shape=filter_shape)\n",
    "    conv_layer = conv_bin(relu_layer, filter, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\n",
    "def residual_block(input_layer, output_channel, first_block=False):\n",
    "    '''\n",
    "    Defines a residual block in ResNet\n",
    "    :param input_layer: 4D tensor\n",
    "    :param output_channel: int. return_tensor.get_shape().as_list()[-1] = output_channel\n",
    "    :param first_block: if this is the first residual block of the whole network\n",
    "    :return: 4D tensor.\n",
    "    '''\n",
    "    input_channel = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    # When it's time to \"shrink\" the image size, we use stride = 2\n",
    "    if input_channel * 2 == output_channel:\n",
    "        increase_dim = True\n",
    "        stride = 2\n",
    "    elif input_channel == output_channel:\n",
    "        increase_dim = False\n",
    "        stride = 1\n",
    "    else:\n",
    "        raise ValueError('Output and input channel does not match in residual blocks!!!')\n",
    "\n",
    "    # The first conv layer of the first residual block does not need to be normalized and relu-ed.\n",
    "    with tf.variable_scope('conv1_in_block'):\n",
    "        if first_block:\n",
    "            filter = create_variables(name='conv', shape=[3, 3, input_channel, output_channel])\n",
    "            conv1 = conv_bin(input_layer, filter=filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        else:\n",
    "            conv1 = bn_relu_conv_layer(input_layer, [3, 3, input_channel, output_channel], stride)\n",
    "\n",
    "    with tf.variable_scope('conv2_in_block'):\n",
    "        conv2 = bn_relu_conv_layer(conv1, [3, 3, output_channel, output_channel], 1)\n",
    "\n",
    "    # When the channels of input layer and conv2 does not match, we add zero pads to increase the\n",
    "    #  depth of input layers\n",
    "    if increase_dim is True:\n",
    "        pooled_input = tf.nn.avg_pool(input_layer, ksize=[1, 2, 2, 1],\n",
    "                                      strides=[1, 2, 2, 1], padding='VALID')\n",
    "        padded_input = tf.pad(pooled_input, [[0, 0], [0, 0], [0, 0], [input_channel // 2,\n",
    "                                                                     input_channel // 2]])\n",
    "    else:\n",
    "        padded_input = input_layer\n",
    "\n",
    "    output = conv2 + padded_input\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "IMG_DEPTH = 3\n",
    "NUM_CLASS = 10\n",
    "\n",
    "BN_EPSILON=0.005\n",
    "\n",
    "reuse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    #num layers = 6n + 2\n",
    "    global init\n",
    "    global summary_op\n",
    "    global error\n",
    "    global accuracy\n",
    "    global outputs\n",
    "    global train_step\n",
    "    global inputs\n",
    "    global targets\n",
    "    global outputs\n",
    "    \n",
    "    inputs = tf.placeholder(tf.float32,[train_batch_size, IMG_HEIGHT,\n",
    "                                                        IMG_WIDTH, IMG_DEPTH], 'inputs')\n",
    "    targets = tf.placeholder(tf.float32, [None, train_data.num_classes], 'targets')\n",
    "    #def inference(input_tensor_batch, n, reuse):\n",
    "\n",
    "    layers = []\n",
    "    with tf.variable_scope('conv0', reuse=reuse):\n",
    "        conv0 = conv_bn_relu_layer(inputs, [3, 3, 3, 16], 1)\n",
    "        layers.append(conv0)\n",
    "\n",
    "    for i in range(n):\n",
    "        with tf.variable_scope('conv1_%d' %i, reuse=reuse):\n",
    "            if i == 0:\n",
    "                conv11 = residual_block(layers[-1], 16, first_block=True)\n",
    "            else:\n",
    "                conv11 = residual_block(layers[-1], 16)\n",
    "            layers.append(conv11)\n",
    "\n",
    "    for i in range(n):\n",
    "        with tf.variable_scope('conv2_%d' %i, reuse=reuse):\n",
    "            conv2 = residual_block(layers[-1], 32)\n",
    "            layers.append(conv2)\n",
    "\n",
    "    for i in range(n):\n",
    "        with tf.variable_scope('conv3_%d' %i, reuse=reuse):\n",
    "            conv3 = residual_block(layers[-1], 64)\n",
    "            layers.append(conv3)\n",
    "        assert conv3.get_shape().as_list()[1:] == [8, 8, 64]\n",
    "\n",
    "    with tf.variable_scope('fc', reuse=reuse):\n",
    "        in_channel = layers[-1].get_shape().as_list()[-1]\n",
    "        bn_layer = batch_normalization_layer(layers[-1], in_channel)\n",
    "        relu_layer = tf.nn.relu(bn_layer)\n",
    "        global_pool = tf.reduce_mean(relu_layer, [1, 2])\n",
    "\n",
    "        assert global_pool.get_shape().as_list()[-1:] == [64]\n",
    "        outputs = fully_connected_layer(global_pool, 64, 10, tf.identity)\n",
    "        \n",
    "    with tf.name_scope('error'):\n",
    "        error = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(outputs, targets))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(\n",
    "                tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), \n",
    "                tf.float32))\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        opt = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.9)\n",
    "        train_step = opt.minimize(error)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    tf.summary.scalar('error', error)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_session(name, num_epoch):\n",
    "    open_file_to_write(name)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        valid_inputs = valid_data.inputs\n",
    "        valid_targets = valid_data.to_one_of_k(valid_data.targets) \n",
    "        sess.run(init)\n",
    "        for e in range(num_epoch):\n",
    "            running_error = 0.\n",
    "            running_accuracy = 0.\n",
    "            start = time.time()\n",
    "            for b, (input_batch, target_batch) in enumerate(train_data):\n",
    "                _, batch_error, batch_acc, summary = sess.run(\n",
    "                    [train_step, error, accuracy, summary_op], \n",
    "                    feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                \n",
    "                running_error += batch_error\n",
    "                running_accuracy += batch_acc\n",
    "\n",
    "                train_writer.add_summary(summary, e * train_data.num_batches + b)\n",
    "                \n",
    "            running_error /= train_data.num_batches\n",
    "            running_accuracy /= train_data.num_batches\n",
    "            print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f}, time(train)={3:.2f}'\n",
    "                  .format(e + 1, running_error, running_accuracy, time.time() - start))\n",
    "            if (e + 1) % 5 == 0:\n",
    "                valid_error = 0.\n",
    "                valid_accuracy = 0.\n",
    "                for b, (input_batch, target_batch) in enumerate(valid_data):\n",
    "                    input_batch = input_batch.reshape((50, IMG_HEIGHT * IMG_WIDTH, IMG_DEPTH), order='F')\n",
    "                    input_batch = input_batch.reshape((50, IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH))\n",
    "                    \n",
    "                    batch_error, batch_acc, summary = sess.run(\n",
    "                        [error, accuracy, summary_op], \n",
    "                        feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                    valid_error += batch_error\n",
    "                    valid_accuracy += batch_acc\n",
    "                    valid_writer.add_summary(summary, e * train_data.num_batches + b)\n",
    "                valid_error /= valid_data.num_batches\n",
    "                valid_accuracy /= valid_data.num_batches\n",
    "                print('                 err(valid)={0:.2f} acc(valid)={1:.2f}'\n",
    "                       .format(valid_error, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.57 acc(train)=0.42, time(train)=1050.05\n",
      "End of epoch 02: err(train)=1.20 acc(train)=0.57, time(train)=925.04\n",
      "End of epoch 03: err(train)=1.03 acc(train)=0.63, time(train)=971.18\n",
      "End of epoch 04: err(train)=0.92 acc(train)=0.68, time(train)=944.71\n",
      "End of epoch 05: err(train)=0.84 acc(train)=0.70, time(train)=874.41\n",
      "                 err(valid)=0.85 acc(valid)=0.70\n",
      "End of epoch 06: err(train)=0.78 acc(train)=0.72, time(train)=865.67\n",
      "End of epoch 07: err(train)=0.74 acc(train)=0.74, time(train)=958.35\n",
      "End of epoch 08: err(train)=0.70 acc(train)=0.75, time(train)=952.35\n",
      "End of epoch 09: err(train)=0.67 acc(train)=0.76, time(train)=938.14\n",
      "End of epoch 10: err(train)=0.65 acc(train)=0.77, time(train)=827.97\n",
      "                 err(valid)=0.74 acc(valid)=0.74\n",
      "End of epoch 11: err(train)=0.62 acc(train)=0.78, time(train)=822.01\n",
      "End of epoch 12: err(train)=0.60 acc(train)=0.79, time(train)=792.40\n",
      "End of epoch 13: err(train)=0.59 acc(train)=0.79, time(train)=784.47\n",
      "End of epoch 14: err(train)=0.57 acc(train)=0.80, time(train)=790.17\n",
      "End of epoch 15: err(train)=0.55 acc(train)=0.81, time(train)=783.33\n",
      "                 err(valid)=0.71 acc(valid)=0.76\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(2)\n",
    "run_session('2-layers', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.57 acc(train)=0.42, time(train)=1412.20\n",
      "End of epoch 02: err(train)=1.22 acc(train)=0.56, time(train)=1354.57\n",
      "End of epoch 03: err(train)=1.05 acc(train)=0.62, time(train)=1372.44\n",
      "End of epoch 04: err(train)=0.95 acc(train)=0.66, time(train)=1346.49\n",
      "End of epoch 05: err(train)=0.87 acc(train)=0.69, time(train)=1562.73\n",
      "                 err(valid)=0.90 acc(valid)=0.68\n",
      "End of epoch 06: err(train)=0.81 acc(train)=0.71, time(train)=1484.73\n",
      "End of epoch 07: err(train)=0.76 acc(train)=0.73, time(train)=1355.07\n",
      "End of epoch 08: err(train)=0.71 acc(train)=0.75, time(train)=1357.23\n",
      "End of epoch 09: err(train)=0.69 acc(train)=0.76, time(train)=1356.40\n",
      "End of epoch 10: err(train)=0.66 acc(train)=0.77, time(train)=1357.75\n",
      "                 err(valid)=0.74 acc(valid)=0.75\n",
      "End of epoch 11: err(train)=0.63 acc(train)=0.78, time(train)=1357.50\n",
      "End of epoch 12: err(train)=0.61 acc(train)=0.78, time(train)=1356.13\n",
      "End of epoch 13: err(train)=0.59 acc(train)=0.79, time(train)=1353.31\n",
      "End of epoch 14: err(train)=0.57 acc(train)=0.80, time(train)=1338.37\n",
      "End of epoch 15: err(train)=0.56 acc(train)=0.80, time(train)=783.47\n",
      "                 err(valid)=0.69 acc(valid)=0.76\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(2)\n",
    "run_session('2-layers-0.01', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.59 acc(train)=0.41, time(train)=1530.84\n",
      "End of epoch 02: err(train)=1.20 acc(train)=0.57, time(train)=3636.97\n",
      "End of epoch 03: err(train)=1.02 acc(train)=0.63, time(train)=1823.44\n",
      "End of epoch 04: err(train)=0.92 acc(train)=0.67, time(train)=1566.55\n",
      "End of epoch 05: err(train)=0.85 acc(train)=0.70, time(train)=1633.16\n",
      "                 err(valid)=0.86 acc(valid)=0.70\n",
      "End of epoch 06: err(train)=0.78 acc(train)=0.72, time(train)=1554.59\n",
      "End of epoch 07: err(train)=0.74 acc(train)=0.74, time(train)=1549.78\n",
      "End of epoch 08: err(train)=0.70 acc(train)=0.75, time(train)=1582.75\n",
      "End of epoch 09: err(train)=0.66 acc(train)=0.77, time(train)=1630.11\n",
      "End of epoch 10: err(train)=0.64 acc(train)=0.78, time(train)=1653.05\n",
      "                 err(valid)=0.71 acc(valid)=0.75\n",
      "End of epoch 11: err(train)=0.61 acc(train)=0.79, time(train)=1538.21\n",
      "End of epoch 12: err(train)=0.60 acc(train)=0.79, time(train)=1595.97\n",
      "End of epoch 13: err(train)=0.57 acc(train)=0.80, time(train)=1665.09\n",
      "End of epoch 14: err(train)=0.56 acc(train)=0.80, time(train)=1582.69\n",
      "End of epoch 15: err(train)=0.54 acc(train)=0.81, time(train)=1436.82\n",
      "                 err(valid)=0.69 acc(valid)=0.77\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(2)\n",
    "run_session('2-layers-0.005', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.54 acc(train)=0.43, time(train)=3271.71\n",
      "End of epoch 02: err(train)=1.12 acc(train)=0.60, time(train)=3213.43\n",
      "End of epoch 03: err(train)=0.95 acc(train)=0.66, time(train)=3200.79\n",
      "End of epoch 04: err(train)=0.84 acc(train)=0.70, time(train)=3205.30\n",
      "End of epoch 05: err(train)=0.75 acc(train)=0.74, time(train)=3203.43\n",
      "                 err(valid)=0.76 acc(valid)=0.73\n",
      "End of epoch 06: err(train)=0.69 acc(train)=0.76, time(train)=3213.07\n",
      "End of epoch 07: err(train)=0.64 acc(train)=0.78, time(train)=3207.26\n",
      "End of epoch 08: err(train)=0.60 acc(train)=0.79, time(train)=3196.89\n",
      "End of epoch 09: err(train)=0.56 acc(train)=0.80, time(train)=3219.21\n",
      "End of epoch 10: err(train)=0.54 acc(train)=0.81, time(train)=3457.45\n",
      "                 err(valid)=0.64 acc(valid)=0.78\n",
      "End of epoch 11: err(train)=0.51 acc(train)=0.82, time(train)=3254.48\n",
      "End of epoch 12: err(train)=0.48 acc(train)=0.83, time(train)=3209.75\n",
      "End of epoch 13: err(train)=0.46 acc(train)=0.84, time(train)=3419.65\n",
      "End of epoch 14: err(train)=0.44 acc(train)=0.85, time(train)=2939.12\n",
      "End of epoch 15: err(train)=0.42 acc(train)=0.85, time(train)=2220.44\n",
      "                 err(valid)=0.66 acc(valid)=0.78\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(5)\n",
    "run_session('5-layers-bin', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.57 acc(train)=0.42, time(train)=4768.38\n",
      "End of epoch 02: err(train)=1.15 acc(train)=0.58, time(train)=3178.44\n",
      "End of epoch 03: err(train)=0.94 acc(train)=0.67, time(train)=3188.64\n",
      "End of epoch 04: err(train)=0.83 acc(train)=0.70, time(train)=3180.61\n",
      "End of epoch 05: err(train)=0.75 acc(train)=0.74, time(train)=3183.27\n",
      "                 err(valid)=0.77 acc(valid)=0.73\n",
      "End of epoch 06: err(train)=0.69 acc(train)=0.76, time(train)=3172.53\n",
      "End of epoch 07: err(train)=0.64 acc(train)=0.78, time(train)=3180.75\n",
      "End of epoch 08: err(train)=0.60 acc(train)=0.79, time(train)=3179.37\n",
      "End of epoch 09: err(train)=0.56 acc(train)=0.80, time(train)=3198.07\n",
      "End of epoch 10: err(train)=0.53 acc(train)=0.82, time(train)=3179.45\n",
      "                 err(valid)=0.66 acc(valid)=0.77\n",
      "End of epoch 11: err(train)=0.51 acc(train)=0.82, time(train)=3179.68\n",
      "End of epoch 12: err(train)=0.48 acc(train)=0.84, time(train)=3177.59\n",
      "End of epoch 13: err(train)=0.47 acc(train)=0.84, time(train)=2895.13\n",
      "End of epoch 14: err(train)=0.44 acc(train)=0.85, time(train)=2203.81\n",
      "End of epoch 15: err(train)=0.42 acc(train)=0.85, time(train)=2405.46\n",
      "                 err(valid)=0.62 acc(valid)=0.79\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "create_model(5)\n",
    "run_session('5-layers-0.05-bin', 15)\n",
    "\n",
    "#learning rate 0.005"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

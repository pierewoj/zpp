{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konwolucja binarna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Konfiguracja pozwalająca na manualne sprawdzenie poprawności inferencji oraz gradientów oraz porównanie ze zwykłą konwolucją"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.29999924  12.39999962]\n",
      " [ 18.59999847  21.69999886]]\n",
      "[[ 11.10000038  14.19999981]\n",
      " [ 20.39999962  23.5       ]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import sparse_ops\n",
    "\n",
    "FLAGS = None\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "      \n",
    "def conv_bin_func(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": \"Conv2D\"}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n",
    "\n",
    "def mysquare(x, name=None):\n",
    "    \n",
    "    with ops.op_scope([x], name, \"Mysquare\") as name:\n",
    "        sqr_x = py_func(np.square,\n",
    "                        [x],\n",
    "                        [tf.float32],\n",
    "                        name=name,\n",
    "                        grad=_MySquareGrad)  # <-- here's the call to the gradient\n",
    "        return sqr_x[0]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 9])\n",
    "x_reshaped = tf.reshape(x, [-1,3,3,1])\n",
    "w = np.zeros([2,2,1,1])\n",
    "w[0:2,0:2,0,0] = np.vstack(([0.1,1],[1,1]))\n",
    "W_conv1 = tf.Variable(tf.cast(w,dtype=tf.float32))\n",
    "G = tf.get_default_graph()\n",
    "with G.gradient_override_map({\"Sign\": \"Identity\"}):\n",
    "            w_shape = tf.shape(W_conv1)\n",
    "            n = tf.cast(tf.reduce_prod(w_shape[0:-1]),tf.float32) \n",
    "            abs = tf.abs(W_conv1)\n",
    "            a = tf.stop_gradient(tf.reduce_sum(abs, [0,1,2])/n)  \n",
    "            absX = tf.abs(x_reshaped)\n",
    "            k = tf.ones(w_shape, dtype=tf.float32) / n\n",
    "            K = conv2d(absX, k)\n",
    "            x_sign = tf.sign(x_reshaped)\n",
    "            w_sign = tf.sign(W_conv1/a)\n",
    "            h_conv_bin = conv2d(x_sign, w_sign)*a*K\n",
    "\n",
    "h_conv = conv2d(x_reshaped, W_conv1)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.as_default()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "numbers = np.reshape(np.array([1,2,3,4,5,6,7,8,9], dtype=np.float32),(1,9))\n",
    "result_bin = h_conv_bin.eval(session=sess, feed_dict={x: numbers})\n",
    "result = h_conv.eval(session=sess, feed_dict={x: numbers})\n",
    "print(result_bin[0,0:2,0:2,0])\n",
    "print(result[0,0:2,0:2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 19.99999809]]\n",
      "\n",
      "  [[ 19.99999809]]]\n",
      "\n",
      "\n",
      " [[[ 19.99999809]]\n",
      "\n",
      "  [[ 19.99999809]]]]\n",
      "[[[[ 12.]]\n",
      "\n",
      "  [[ 16.]]]\n",
      "\n",
      "\n",
      " [[[ 24.]]\n",
      "\n",
      "  [[ 28.]]]]\n"
     ]
    }
   ],
   "source": [
    "var_grad_bin = tf.gradients(h_conv_bin, W_conv1)[0]\n",
    "gradients_bin = var_grad_bin.eval(session=sess, feed_dict={x: np.reshape(numbers,(1,9))})\n",
    "var_grad = tf.gradients(h_conv, W_conv1)[0]\n",
    "gradients = var_grad.eval(session=sess, feed_dict={x: np.reshape(numbers,(1,9))})\n",
    "print(gradients_bin)\n",
    "print(gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
